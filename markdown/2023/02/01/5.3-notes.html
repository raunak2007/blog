<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">5.3 and 5.4 Blog Post Reflection</h1><p class="page-description">Unit 5.3 and 5.4 Hacks</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-02-01T00:00:00-06:00" itemprop="datePublished">
        Feb 1, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/csp-fast-pages/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="big-idea-53-computing-bias">Big Idea 5.3 Computing Bias</h1>

<h3 id="crossover-group-work---answering-the-prompted-questions">Crossover Group Work - Answering the prompted questions:</h3>

<ol>
  <li>
    <p>After googling “What age groups use Facebook” vs “… TikTok”?”, we came to the conclusion that the average Facebook user is in the range of 25-34, and TikTok between ages 10-19. We are arguing that the differences between these average ages is simply due to a generation gap. As it can be seen through other Facebook-owned companies, such as Instagram, the average age is again in the mid teens because of how well it has adapted to a newer generation.</p>
  </li>
  <li>
    <p>Yes, the female voices in AI assistants were purposeful implementations, and many take it in a manner that is offensive. Companies believe the female voice is more soothing and appreciative, but probably failed to take into account the derogatory meanings behind such a product. However, these assistants do have the options to be sounded as men as well, so people just need to change the default settings</p>
  </li>
  <li>
    <p>An algorithm that influences our decisions is that of TikTok, which spreads trends and awareness with incredible speed and popularity.</p>
  </li>
</ol>

<h3 id="pairs">Pairs:</h3>

<ol>
  <li>Although the owner is jokingly upset that the software doesn’t work on him, it is difficult to tell whether or not he is genuinely calling out HP for being “racist”. Our group hypothesizes that the software was only tested on people of lighter skin tone, and therefore wasn’t able to recognize a darker skin tone.</li>
</ol>

<p>Brief Summary of Reading:</p>

<p>The reading discusses the topic of computer bias and its effects, specifically in the context of algorithms created by programmers. It raises questions about the possibility of intentional or purposeful bias in algorithms and technology, as well as the potential harm it can cause. The article looks at examples such as age group preferences for social media platforms, the use of female voices for virtual assistants, and an instance of a computer that was deemed “racist”. The article invites discussion and reflection on these topics, asking questions about the intentionality of the bias, the potential harm it may cause, and what steps can be taken to produce a better outcome.</p>


  </div><a class="u-url" href="/csp-fast-pages/markdown/2023/02/01/5.3-notes.html" hidden></a>
</article>
